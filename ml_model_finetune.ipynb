{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5341c1be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset...\n",
      "Dataset size  9214\n",
      "Loading dataset...\n",
      "Model           SVC  LinearSVC       XGB  LightGBM  LogisticReg\n",
      "accuracy   0.883764   0.881593  0.815391  0.816910     0.880834\n",
      "precision  0.880272   0.880544  0.770845  0.827487     0.879024\n",
      "recall     0.888000   0.882481  0.897100  0.802796     0.882941\n",
      "f1_score   0.884048   0.881483  0.829120  0.813998     0.880898\n"
     ]
    }
   ],
   "source": [
    "# Code reference: https://github.com/algosenses/Stock_Market_Sentiment_Analysis/blob/master/model_ml.py\n",
    "# The modified code gives access to the fitted models for finetune. \n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "import pickle\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, KFold\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "from sklearn.utils.extmath import density\n",
    "from sklearn import svm\n",
    "from sklearn import naive_bayes\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from lightgbm import LGBMClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.utils import shuffle\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "from config import *\n",
    "def load_dataset():\n",
    "    pos_file = os.path.join(data_path, pos_corpus)\n",
    "    neg_file = os.path.join(data_path, neg_corpus)\n",
    "\n",
    "    pos_sents = []\n",
    "    with open(pos_file, 'r', encoding='utf-8') as f:\n",
    "        for sent in f:\n",
    "            pos_sents.append(sent.replace('\\n', ''))\n",
    "\n",
    "    neg_sents = []\n",
    "    with open(neg_file, 'r', encoding='utf-8') as f:\n",
    "        for sent in f:\n",
    "            neg_sents.append(sent.replace('\\n', ''))\n",
    "\n",
    "    balance_len = min(len(pos_sents), len(neg_sents))\n",
    "\n",
    "    pos_df = pd.DataFrame(pos_sents, columns=['text_seg'])\n",
    "    pos_df['polarity'] = 1\n",
    "    pos_df = pos_df[:balance_len]\n",
    "\n",
    "    neg_df = pd.DataFrame(neg_sents, columns=['text_seg'])\n",
    "    neg_df['polarity'] = 0\n",
    "    neg_df = neg_df[:balance_len]\n",
    "\n",
    "    return pd.concat([pos_df, neg_df]).reset_index(drop=True)\n",
    "\n",
    "\n",
    "print('Loading dataset...')\n",
    "\n",
    "dataset = load_dataset()\n",
    "\n",
    "print('Dataset size ', len(dataset))\n",
    "\n",
    "\n",
    "\n",
    "def load_dataset_tokenized():\n",
    "    pos_file = os.path.join(data_path, pos_corpus)\n",
    "    neg_file = os.path.join(data_path, neg_corpus)\n",
    "\n",
    "    pos_sents = []\n",
    "    with open(pos_file, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            tokens = line.split(' ')\n",
    "            sent = []\n",
    "            for t in tokens:\n",
    "                if t.strip():\n",
    "                    sent.append(t.strip())\n",
    "            pos_sents.append(sent)\n",
    "\n",
    "    neg_sents = []\n",
    "    with open(neg_file, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            tokens = line.split(' ')\n",
    "            sent = []\n",
    "            for t in tokens:\n",
    "                if t.strip():\n",
    "                    sent.append(t.strip())\n",
    "            neg_sents.append(sent)\n",
    "\n",
    "    balance_len = min(len(pos_sents), len(neg_sents))\n",
    "\n",
    "    texts = pos_sents + neg_sents\n",
    "    labels = [1] * balance_len + [0] * balance_len\n",
    "\n",
    "    return texts, labels\n",
    "\n",
    "\n",
    "def KFold_validation(clf, X, y):\n",
    "    acc = []\n",
    "    precision, recall, f1_score = [], [], []\n",
    "\n",
    "\n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    for train, test in kf.split(X):\n",
    "        X_train = [X[i] for i in train]\n",
    "        X_test = [X[i] for i in test]\n",
    "        y_train = [y[i] for i in train]\n",
    "        y_test = [y[i] for i in test]\n",
    "\n",
    "        def dummy_fun(doc):\n",
    "            return doc\n",
    "\n",
    "        vectorizer = TfidfVectorizer(analyzer='word',\n",
    "                                     tokenizer=dummy_fun,\n",
    "                                     preprocessor=dummy_fun,\n",
    "                                     token_pattern=None)\n",
    "\n",
    "        vectorizer.fit(X_train)\n",
    "        X_train = vectorizer.transform(X_train)\n",
    "        X_test = vectorizer.transform(X_test)\n",
    "\n",
    "        clf.fit(X_train, y_train)\n",
    "        preds = clf.predict(X_test)\n",
    "\n",
    "        acc.append(metrics.accuracy_score(y_test, preds))\n",
    "        precision.append(metrics.precision_score(y_test, preds))\n",
    "        recall.append(metrics.recall_score(y_test, preds))\n",
    "        f1_score.append(metrics.f1_score(y_test, preds))\n",
    "\n",
    "\n",
    "    return clf, (np.mean(acc), np.mean(precision), np.mean(recall), np.mean(f1_score))\n",
    "\n",
    "\n",
    "def benchmark_clfs():\n",
    "    \n",
    "    \n",
    "    print('Loading dataset...')\n",
    "\n",
    "    X, y = load_dataset_tokenized()\n",
    "\n",
    "    classifiers = [\n",
    "        ('SVC', svm.SVC()),\n",
    "        ('LinearSVC', svm.LinearSVC()),\n",
    "        ('XGB',XGBClassifier()),\n",
    "        ('LightGBM',LGBMClassifier()),\n",
    "        ('LogisticReg', LogisticRegression())\n",
    "\n",
    "    ]\n",
    "\n",
    "    cols = ['Model', 'accuracy',  'precision', 'recall', 'f1_score']\n",
    "    scores = []\n",
    "    model_dict = {}\n",
    "    \n",
    "    for name, clf in classifiers:\n",
    "        model, score = KFold_validation(clf, X, y)\n",
    "        model_dict[name] = model\n",
    "        row = [name]\n",
    "        row.extend(score)\n",
    "        scores.append(row)\n",
    "\n",
    "    df = pd.DataFrame(scores, columns=cols).T\n",
    "    df.columns = df.iloc[0]\n",
    "    df.drop(df.index[[0]], inplace=True)\n",
    "    df = df.apply(pd.to_numeric, errors='ignore')\n",
    "\n",
    "    return model_dict ,df\n",
    "\n",
    "def dummy_fun(doc):\n",
    "        return doc\n",
    "\n",
    "def eval_model():\n",
    "    print('Loading dataset...')\n",
    "\n",
    "    X, y = load_dataset_tokenized()\n",
    "\n",
    "    clf = svm.LinearSVC()\n",
    "\n",
    "    vectorizer = TfidfVectorizer(analyzer='word',\n",
    "                                 tokenizer=dummy_fun,\n",
    "                                 preprocessor=dummy_fun,\n",
    "                                 token_pattern=None)\n",
    "    \n",
    "    X = vectorizer.fit_transform(X)\n",
    "\n",
    "    print('Train model...')\n",
    "    clf.fit(X, y)\n",
    "\n",
    "    print('Loading comments...')\n",
    "\n",
    "    df_raw = pd.read_csv(test_path)\n",
    "    texts = df_raw['title_seg']\n",
    "    texts = vectorizer.transform(texts.values.astype('U')) \n",
    "    preds = clf.predict(texts)\n",
    "\n",
    "    df_raw['polarity'] = preds\n",
    "\n",
    "ml_models, scores = benchmark_clfs()\n",
    "print(scores)\n",
    "scores.to_csv(ml_performance_path, float_format='%.4f')\n",
    "\n",
    "#eval_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d815c303",
   "metadata": {},
   "outputs": [],
   "source": [
    "SVC = ml_models['SVC']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c31be73d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.89      0.89       946\n",
      "           1       0.88      0.88      0.88       897\n",
      "\n",
      "    accuracy                           0.89      1843\n",
      "   macro avg       0.89      0.89      0.89      1843\n",
      "weighted avg       0.89      0.89      0.89      1843\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "def dummy_fun(doc):\n",
    "    return doc\n",
    "\n",
    "# Load the dataset\n",
    "X, y = load_dataset_tokenized()\n",
    "\n",
    "# Initialize the vectorizer\n",
    "vectorizer = TfidfVectorizer(analyzer='word',\n",
    "                             tokenizer=dummy_fun,\n",
    "                             preprocessor=dummy_fun,\n",
    "                             token_pattern=None)\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "vectorizer.fit(X_train)\n",
    "# Transform the training and test data\n",
    "X_train = vectorizer.transform(X_train)\n",
    "X_test = vectorizer.transform(X_test)\n",
    "\n",
    "# Define the parameter grid for grid search\n",
    "param_grid = {\n",
    "    'C': [0.1, 1, 10],\n",
    "    'kernel': ['linear', 'rbf'],\n",
    "    'gamma': ['scale', 'auto']\n",
    "}\n",
    "\n",
    "# Perform grid search to find the best hyperparameters\n",
    "grid_search = GridSearchCV(estimator=SVC, param_grid=param_grid, cv=5)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best model and its hyperparameters\n",
    "best_clf = grid_search.best_estimator_\n",
    "best_params = grid_search.best_params_\n",
    "\n",
    "# Make predictions on the test set using the best model\n",
    "preds = best_clf.predict(X_test)\n",
    "\n",
    "# Print the classification report\n",
    "print(classification_report(y_test, preds))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2296cff1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 10, 'gamma': 'scale', 'kernel': 'rbf'}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_params"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
